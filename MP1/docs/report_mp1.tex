% setup the document and include packages
\documentclass{article}[12pt]
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{ntheorem}
\usepackage{algorithm2e}
\usepackage{float}
\usepackage{caption}
\usepackage{fancyvrb}
\usepackage[dvipsnames]{xcolor}
\usepackage[section]{placeins}
\usepackage[toc,page]{appendix}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\urlstyle{same}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

% define Continue for algorithms
\SetKw{Continue}{continue}

% Define custome verbatim command to insert maze text file results
\RecustomVerbatimCommand{\BVerbatimInput}{VerbatimInput}%
{fontsize=\footnotesize,
 %
 frame=lines,  % top and bottom rule only
 framesep=2em, % separation between frame and text
 rulecolor=\color{Black},
 %
 %label=\fbox{\color{Black}data.txt},
 labelposition=topline,
 %
 %commandchars=\|\(\), % escape character and argument delimiters for
                      % commands within the verbatim
 %commentchar=*        % comment character
}

% redefine QED symbol
\renewcommand{\qedsymbol}{\rule{0.7em}{0.7em}}

% define lemma and result theorem-styled sections
\newtheorem{lemma}{Lemma}[section]
\newtheorem{result}{Result}[section]

% Don't print the semicolon in algorithms
\DontPrintSemicolon

% define the title that will be used in the report
\title{CS 440 MP1 \\ Section Q4 \\ 4 Credits}
\author{
Christian Howard \\ howard28@illinois.edu
\and
Luke Pitstick \\ pitstck2@illinois.edu
\and
Liuyi Shi \\ liuyis2@illinois.edu
}
\date{} % don't set a date because we don't need this shit


% start the document
\begin{document}
   
   % create the title page 
   \maketitle
   \begin{abstract}
   Within this report, we investigate creating agents that use different path planning algorithms and do an analysis of how they compare for a set of sample problems. \textbf{Insert summary of results}. We later apply $A^*$ algorithms to guide an agent to solving the  Sokoban puzzle. \textbf{Insert summary of results}.
   \end{abstract}
   \newpage
   
   % create table of contents on separate page
   \tableofcontents
   \newpage
   
   % start section covering work on Part 1.1
   \section{Part 1 - Multi-Goal Search}
   Within this section, we investigate using search algorithms to tackle single-goal and multi-goal objectives. To handle this problem, the provided maze is processed into a graph, $G_m$, that can be used to figure out what actions a given agent can take and when they reach some goal node. To model the motion of some agent, we define the state, $\boldsymbol{x}$, as the following:  
   
   \begin{align*}
   \boldsymbol{x} = \left( p, b_1, b_2, \cdots, b_n \right)
   \end{align*}
   
   where $p$ is an index representing the graph node the agent is on and $b_k$ represents a Boolean variable that is $1$ (true) when the agent has passed through the $k$\textsuperscript{th} goal point at some point prior and $0$ (false) otherwise. Note that this state is always implicitly dependent on the maze graph, $G_m$. We know an agent has completed a maze when it reaches a state that satisfies the following:
   
   \begin{align*}
   b_1 \wedge b_2 \wedge \cdots \wedge b_n = 1
   \end{align*}
   
   To model the step by step motion of an agent, the transition function is defined as the following:
   
   \RestyleAlgo{boxruled}
	\begin{algorithm}[H]
	\caption{Transition Function - Multi-goal }
		 \KwData{State, $\boldsymbol{x}$ }
		 \KwData{Action, $a$ }
		 \KwData{Maze Graph, $G_m$ }
		 \KwData{Goal Node Set, $V_g = \lbrace p_1, p_2, \cdots, p_n\rbrace$ }
		 \KwResult{New State, $\boldsymbol{x}_n$}
		 \;
		 
		 \tcp{Set the new state with the \\current state's boolean configuration}
		 \For{$k \in \lbrace 1, 2, \cdots, |V_g| \rbrace$}{
		 	$\boldsymbol{x}_n(b_k) = \boldsymbol{x}(b_k)$
		 }
		 \;
		 
		 \tcp{Update position in maze given the action $a$}
		 $\boldsymbol{x}_n(p) = \text{getNextPosition}\left(\boldsymbol{x},a,G_m\right)$
		 \;
		 \;
		 
		 \tcp{Check if new position is in goal node set
		 \\If so, find index associated with goal node and 
		 \\set corresponding boolean to $1$}
		 \If{ $\boldsymbol{x}_n(p) \in V_g$ }{
		 	Get $m \ni \boldsymbol{x}_n(p) = p_m$\;
		 	Set $\boldsymbol{x}_n(b_m) = 1$
		 }
		 \;
		 \Return $\boldsymbol{x}_n$
	\end{algorithm}
	
	Given the state representation and transition function described above, we are now able to implement and test our search-based agents. That said, we are now able to dive into solving each challenge of Part 1.
	
	\subsection{Part 1.1 - Basic Pathfinding}
   In this first challenge for Part 1, the goal is to implement search algorithms for navigating through a maze environment to a single goal location. For this challenge, we have implemented the following search algorithms:
   
   \begin{itemize}
   \item Depth-First Search
   \item Breadth-First Search
   \item Greedy Best-First Search
   \item A\textsuperscript{*} Search
   \end{itemize}
   
   For Greedy and A\textsuperscript{*}, we have also set their Heuristic Function as the Manhattan Distance metric, defined as the following:
   
   \begin{align*}
   d_M(u,v) = |u - v|_1
   \end{align*}
   
   where $u, v \in \mathbb{R}^2$ represent positions in the maze we want the distance between and $|\cdot|_1$ is the $L_1$ norm. Using this formula, the heuristic function will be:
   
   \begin{align*}
   h(n) = d_M(n,g)
\end{align*}      
   
   where $n$ is the 2-D position of the current agent's position and $g$ is the 2-D position of the goal point. Given the above search strategies and heuristic, Table \ref{tab:sol11} and Table \ref{tab:nnode11} show the stats between each method for each of the provided mazes:
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l | l  }
   \hline
    & Medium Maze & Big Maze & Open Maze\\
    \hline \hline 
   Depth-First Search & 124 & 474 & 59 \\
   Breadth-First Search & 68 & 148 & 45 \\
   Greedy Best-First Search & 68 & 222 & 77 \\
   A\textsuperscript{*} Search & 68 & 148 & 45 \\
   \hline
   \end{tabular}
   \caption{Solution Path Cost} \label{tab:sol11}
   \end{table}
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l | l  }
   \hline
    & Medium Maze & Big Maze & Open Maze\\
    \hline \hline 
   Depth-First Search & 198 & 1029 & 319 \\
   Breadth-First Search & 345 & 1259 & 523 \\
   Greedy Best-First Search & 77 & 311 & 27761 \\
   A\textsuperscript{*} Search & 202 & 1495 & 667 \\
   \hline
   \end{tabular}
   \caption{Number of Nodes Expanded} \label{tab:nnode11}
   \end{table}
   
   Note that Appendix \ref{appendix:p11} contains visuals for the solution paths for each case. Now as we can see in the tables, Depth-First Search (DFS) tended to arrive at a solution to a given maze quickly but at the expense of a sub-optimal path cost. We can note that Breadth First Search (BFS) and A* both, as expected, produced optimal path costs but it is interesting to note that for the Big Maze and Open Maze, BFS actually reached the optimal solution faster. It seems feasible that the Manhattan distance heuristic would, at times, take A* in a path that would lead to dead ends, in turn requiring A* to expand more nodes than BFS would have to. 
   
   One other thing to note was the interesting characteristics of the Greedy Search. We can see that on one end, it reached an optimal result in a very low number of expanded nodes for the Medium Maze. On the other end, it reaches a sub-optimal path cost after expanding a huge number of states in the Open Maze. Greedy obviously lacks robustness and this can be suspected due to the fact it does not take into account how far it has come but only thinks about how far away it thinks it is. Given this one sided thinking, the agent can get too excited being "close" to the goal even though they may be winding through a lot of poor sub-paths.
   
    
   
    \newpage
   \subsection{Part 1.2 - Search with Multiple Dots}
The goal of this part was to build heuristics for the A* algorithm that would allow an agent to tackle a set of multi-goal problems in a reasonable time frame. The heuristic being used for this section is one based on the Convex Hull. 

Let us first define the distance metric, $d_{\text{ch}}(\cdot,\cdot,\cdot)$, as the following:

\begin{align*}
d_{\text{ch}}(x,y, \beta) &= \beta |x-y|_2+ \left(1-\beta\right) |x-y|_1 
\end{align*}

where $|\cdot|_1$ is the $L_1$ norm, $|\cdot|_2$ is the $L_2$, norm, and $\beta \in [0,1]$ is a tuning parameter. Let us define $p$ as the current location of the agent and define $V_u = \lbrace \hat{g}_1, \hat{g}_2, \cdots, \hat{g}_m \rbrace$ as the set of $m$ unvisited goal points. Let us then compute the convex hull of $\lbrace p \rbrace \bigcup V_u$, defined as:

\begin{align*}
\left(V_{\text{ch}}, E_{\text{ch}} \right) = \text{ConvexHull}\left(\lbrace p \rbrace \bigcup V_u \right)
\end{align*}

where $V_{\text{ch}}$ are the vertices on the convex hull of the input set and $E_{\text{ch}}$ is the edge set of 2-tuples such that $E_{\text{ch}} = \lbrace (x,y): x,y \text{ are ordered vertices of some edge} \rbrace$. For this heuristic, we will remove an edge from $E_{\text{ch}}$ to ensure we only touch each point on the convex hull once. We will call the resulting edge set as $\hat{E}_{\text{ch}}$ and will define it in the following way. 

If $p \notin V_{\text{ch}}$, $\hat{E}_{\text{ch}}$ will be equivalent to $E_{\text{ch}}$ with the largest edge from $E_{\text{ch}}$ removed and then an edge of minimal distance between $p$ and some $v \in V_{\text{ch}}$ added. If $p \in V_{\text{ch}}$, $\hat{E}_{\text{ch}}$ will be equivalent to $E_{\text{ch}}$ with the largest edge that has the vertex $p$ on it being removed. Given we have produced this new edge set $\hat{E}_{\text{ch}}$, the heuristic is then computed as:

\begin{align*}
h_{\text{ch}}(p) = \sum_{(x,y) \in \hat{E}_{\text{ch}}} d_{\text{ch}}(x,y, \beta) + |V_I| - \frac{20}{|V_u|}
\end{align*}

where $V_I$ represents the set of goal points on the interior of the convex hull. This heuristic is admissible because, looking at the first term, the convex hull based distance using the edge set $\hat{E}_{\text{ch}}$ represents the shortest distance possible between points on the convex hull. 

The secondary term is then just multiplying the number of goal points within the convex hull by the minimum distance of 1 to get to any neighboring goal point. This second term is a lower bound on the distance it will take to touch each of the interior goal points from any point along the convex hull. The last term removes from the distance based on the number of points the agent has yet to visit. This third term is meant to help add variation in the boolean portion of the state space while ensuring the heuristic is admissible. This last term essentially subtracts more when there are less goals left, making the distance to go appear less and in turn making a node get selected earlier. Now in all, these three terms together in turn under estimate the minimal distance the agent will need to travel to touch each goal point, making the heuristic admissible. The results using this heuristic can be found in Table \ref{tab:sol12} and Table \ref{tab:nnode12}.

\begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   39 & 153 & 207 \\
   \hline
   \end{tabular}
   \caption{Solution Path Cost - A* with $h_{\text{ch}}(p)$} \label{tab:sol12}
   \end{table}
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   507 & 1,474,789 &  217,424,792\\
   \hline
   \end{tabular}
   \caption{Number of Nodes Expanded - A* with $h_{\text{ch}}(p)$} \label{tab:nnode12}
   \end{table}

   \newpage
   \subsection{Part 1 Extra Credit - Sub-optimal Heuristics}
   \subsubsection{Fast Convex Hull Heuristic}
   The heuristic in this section is another Convex Hull based Heuristic that modifies some of the logic used in the Part 1.2 definition that makes it not provably admissible. This heuristic can be defined as the following:
   
   \begin{align*}
   h_{\text{fch}}(p) &= \left(1 + \beta_1 \right) \left( \sum_{ (x,y) \in E_{\text{ch}} } |x - y|_2 - \max_{ (x,y) \in E_{\text{ch}} } |x - y|_2 \right) + \beta_2 |V_I|
   \end{align*}
   
   where $\beta_1, \beta_2 \geq 0$ are tuning parameters, $E_{\text{ch}}$ is the unmodified convex hull edge set, as defined earlier, and $V_I$ represents goal points within the convex hull. For testing, $\beta_1 = \frac{1}{\sqrt{2}}$ and $\beta_2 = 2$. Table \ref{tab:solfch} and Table \ref{tab:nnodefch} show this heuristic produces great results in much faster speeds, compared to the admissible Convex Hull Heuristic from Part 1.2, while still achieving near optimal cost.
   
   
\begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   38 & 149 & 207 \\
   \hline
   \end{tabular}
   \caption{Solution Path Cost - A* with $h_{\text{fch}}(p)$} \label{tab:solfch}
   \end{table}
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   90 & 424,221 &  6,852,599\\
   \hline
   \end{tabular}
   \caption{Number of Nodes Expanded - A* with $h_{\text{fch}}(p)$} \label{tab:nnodefch}
   \end{table}   
   
   \subsubsection{Blended Heuristic}
   The idea of this heuristic was to blend two heuristics, one that is non-admissible and another that is admissible. The blending procedure implemented used the following formulation:
   
   \begin{align*}
   h_{\text{blend}}(p) &= \left( 1 - \beta \right) h_{MM}(p) + \beta h_{max}(p) \\
   h_{\text{MM}}(p) &= \sum_{ g \in V_{u} } |p - g|_1 \\
   h_{\text{max}}(p) &= \max_{g \in V_{u} } |p - g|_1 \\
   \beta &= \sigma\left( 20 \frac{|V_g| - |V_u|}{|V_g|} - 10 \right) \\
   \sigma(z) &= \left(1 + e^{-z} \right)^{-1}
   \end{align*}
   
   Table \ref{tab:solblend} and Table \ref{tab:nnodeblend} show the performance of this blended heuristic on the same mazes from Part 1.2. We can see that this Blended Heuristic achieved decent solutions for each of the mazes and did so after visiting a lot less nodes than the admissible heuristic from Part 1.2. 
   
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   45 & 171 & 265 \\
   \hline
   \end{tabular}
   \caption{Solution Path Cost - A* with $h_{\text{blend}}(p)$} \label{tab:solblend}
   \end{table}
   
   \begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l  }
   \hline
    Tiny Search & Small Search & Medium Search\\
    \hline \hline 
   1104 & 224,780 &  2,295,759\\
   \hline
   \end{tabular}
   \caption{Number of Nodes Expanded - A* with $h_{\text{blend}}(p)$} \label{tab:nnodeblend}
   \end{table}   
   
   
   \newpage
   \section{Part 2 - Sokoban}
   \subsection{State and Transition Model Definitions}
   Within this section, the goal is to develop an agent that is capable of solving the Sokoban puzzle problem for a set of input puzzles. To handle this problem, the state representation has been defined as the following:
   
   \begin{align*}
   \boldsymbol{x} = \left( p, b_1, b_2, \cdots, b_n \right)
   \end{align*}
   
   where in this case $p$ is the position of the agent, represented as a graph node index, and $b_k$ represents the position of the $k$\textsuperscript{th} box's position, represented as a graph node index, within the puzzle environment. Note that, as before, the input puzzle is processed to construct a graph representation which is in turn an implicit part of the state and environment representation for this problem. To know when the agent has found a Goal State, the following condition must be met:
   
   \begin{align*}
   \left(b_1 \in V_g \right) \wedge \left(b_2 \in V_g \right) \wedge \cdots \wedge \left(b_n \in V_g \right) = 1
   \end{align*}
   
   where $V_g = \lbrace g_1, g_2, \cdots, g_n\rbrace$ is the set of goal points within the puzzle we can place a box. The next step in formulating this problem is describing the Transition Model for the agent and what actions an agent can take based on its state. Algorithm \ref{algo:tmodel} describes the Transition Model for Sokoban given our state representation, while Algorithm \ref{algo:aset} refers to how we get the feasible action set for an agent given its current state. With these pieces described, we can readily approach solving Sokoban using the search methods discussed earlier.
   
   \RestyleAlgo{boxruled}
	\begin{algorithm}
		 \KwData{State, $\boldsymbol{x}$ }
		 \KwData{Action, $a$, assumed to be valid }
		 \KwData{Maze Graph, $G_m$ }
		 \KwResult{New State, $\boldsymbol{x}_n$}
		 \;
		 
		 \tcp{Set the new state with the \\current state's box configuration}
		 \For{$k \in \lbrace 1, 2, \cdots, |V_g| \rbrace$}{
		 	$\boldsymbol{x}_n(b_k) = \boldsymbol{x}(b_k)$
		 }
		 \;
		 
		 \tcp{Update position in maze given the action $a$}
		 $\boldsymbol{x}_n(p) =  \text{getNextPosition}\left(\boldsymbol{x},a,G_m\right)$
		 \;
		 \;
		 
		 \tcp{Check if new position is in equivalent to\\
		 the position of one of the boxes. If so update\\
		 the location of the box using the same action}
		 \If{ $\boldsymbol{x}_n(p) \in \lbrace \boldsymbol{x}_n(b_1), \boldsymbol{x}_n(b_2), \cdots, \boldsymbol{x}_n(b_n) \rbrace$ }{
		 	Get $i \ni \boldsymbol{x}_n(p) = \boldsymbol{x}_n(b_i)$\;
		 	Set $\boldsymbol{x}_n(b_i) = \text{getNextPosition}\left(\boldsymbol{x}_n(b_i), a, G_m\right)$
		 }
		 \;
		 \Return $\boldsymbol{x}_n$
		 \caption{Sokoban Transition Model Algorithm}
		 \label{algo:tmodel}
	\end{algorithm}	
	
	\RestyleAlgo{boxruled}
	\begin{algorithm}
		 \KwData{State, $\boldsymbol{x}$ }
		 \KwData{Maze Graph, $G_m$ }
		 \KwData{Goal Node Set, $V_g = \lbrace g_1, g_2, \cdots, g_n\rbrace$ }
		 \KwResult{Action Set, $A$}
		 \;
		 
		 \tcp{Get set of box positions}
		 $B_p = \text{getBoxPositions}\left(\boldsymbol{x}\right)$\;\;
		 
		 \tcp{Initialize Action Set as the one based on the Connectivity}
		 $A = \text{getActionsFromConnectivity}\left(\boldsymbol{x}(p), G_m\right)$ \;\;
		 
		 \tcp{Loop through possible actions and check they are valid\\
		 given the rules of Sokoban}
		 \For{$a \in A$}{
		 	
		 	\tcp{Get the next node in the graph the \\ agent would be going to}
		 	$p_n = \text{getNextPosition}\left(\boldsymbol{x},a,G_m\right)$\;\;
		 	
		 	\tcp{Check if $p_n$ is the position of a box}
		 	\If{$p_n \in B_p$}{
		 		\tcp{Update position of matching box using action $a$ \\and check if it is a valid position}
		 		$u =  \text{getNextPosition}\left(p_n,a,G_m\right)$\;\;
		 		
		 		\tcp{If new box position interferes with another box \\or the wall, remove $a$ from the action set $A$}
		 		\If{ $u \in B_p$ or $\text{isWall}\left(u,G_m\right)$ }{
		 			$A \leftarrow A \setminus \lbrace a\rbrace$
		 		}
		 	}
		 }
		 \;
		 
		 \tcp{Return the desired Action Set}
		 \Return $A$
		 
		 \caption{Sokoban Action Set Retrieval Algorithm}
		 \label{algo:aset}
	\end{algorithm}
	
	\newpage
	\subsection{Solving Sokoban with Breadth First Search}
	Using our state representation and the transition model for the agent, it becomes simple to apply BFS to tackling Sokoban problems. With this, the results of this BFS against the set of Sokoban puzzles provided can be found in Table \ref{tab:sokbfs}. Animations of their solution, in the form of GIFs, can be found in the project zip with their identifiers as \textbf{bfs\_sokoban*.gif}. As expected, BFS solved the Sokoban problems using how we modeled the state and environment, though Sokoban 4 did expand a considerable number of states.
	
	\begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l | l | l }
   \hline
    & Sokoban 1 & Sokoban 2 & Sokoban 3 & Sokoban 4\\
    \hline \hline 
   Number of Moves & 8 & 144 & 34 & 72 \\
   Nodes Expanded & 46 & 2,038,936 & 2,076,600 & 176,495,868\\
   Run Time & 0.13 s & 3.47 s & 4.70 s & 207.12 s\\
   \hline
   \end{tabular}
   \caption{Sokoban solved by BFS} \label{tab:sokbfs}
   \end{table}	
	
	\subsection{Solving Sokoban with A*}
	To tackle Sokoban, we go over a heuristic for A* and the results we achieve solving Sokoban. To keep things simple, the heuristic is defined as the following:
	
	\begin{align*}
	h_{\text{nearest}}(p) &= \min_{b \in B_p} d_{M}(p, b) + \sum_{b \in B_p} \min_{g \in V_g} d_{M}(b,g)
	\end{align*}
	
	where $B_p = \text{getBoxPositions}\left(\boldsymbol{x}\right)$ and $V_g$ represents the set of goal point locations for the boxes. This heuristic is admissible. The first term, representing the distance the agent has left to move to reach the boxes, is underestimating the distance the agent has to go since it is only looking at the distance to the nearest box. The second term also acts as a sum of the lower bounds to the distance the agent would have to push a given box $b$ to some goal $g$. This is a lower bound in the second term, as formulated, because the nearest goal point to some box $b$ is not necessarily a goal point the box can reach, nor is that goal point necessarily one that can be used to solve the overall puzzle. The sum of these components together in turn produces an underestimate of the distance the agent has left to travel before completion of the puzzle, making the heuristic admissible.
	
	With this, the results of this A* formulation against the set of Sokoban puzzles provided can be found in Table \ref{tab:sokastar}. Animations of their solution, in the form of GIFs, can be found in the project zip with their identifiers as \textbf{astar\_nearest\_sokoban*.gif}. Watching the animations, it is interesting to see how the agent tackled trickier puzzles like Sokoban 2 and Sokoban 4 where the solution requires more seemingly long term thinking, i.e. making sure moves you make now allow for you to make moves later on boxes that are more constrained. Fortunately, the heuristic managed to solve all these puzzles in a reasonable time frame, though we expect there are superior heuristics for managing Sokoban 2 and Sokoban 4.
	
	\begin{table}[ht]
   \centering
   \begin{tabular}{l | l | l | l | l }
   \hline
    & Sokoban 1 & Sokoban 2 & Sokoban 3 & Sokoban 4\\
    \hline \hline 
   Number of Moves & 10 & 148 & 36 & 72 \\
   Nodes Expanded & 36 & 517,584 & 146,259 & 11,404,258\\
   Run Time & 0.14 s & 2.49 s & 0.95 s & 40.16 s\\
   \hline
   \end{tabular}
   \caption{Sokoban solved by A* using $h_{\text{nearest}}(p)$} \label{tab:sokastar}
   \end{table}
   
   
   \subsection{Comparison of Results}
   By checking Table \ref{tab:sokbfs} and Table \ref{tab:sokastar}, we can draw some obvious comparisons. First, BFS always achieved an optimal result and A* was right near it, though it might have missed the absolute optimal solution due to the repeated state detection. Additionally, A* performed much faster than BFS in terms of number of nodes expanded. The run-time comparison between BFS and A* also followed that trend generally, though A* did not run as many multiples faster than BFS with respect to run-time as it did number of nodes expanded. This makes sense because the heuristic computation of A* is going to cost CPU time that BFS does not have to worry about.  
   
\newpage
   \section{List of Potential Extra Credit}
   \begin{itemize}
   \item Animations for all solutions throughout the report, including Sokoban problems
   \item Extra sub-optimal heuristics for Part 1.2
\end{itemize}      
   
   \newpage
\begin{appendices}

\section{Maze Solutions for Part 1.1}
   \label{appendix:p11}
   
   % solutions for BFS
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/bfs/bfs_mediumMaze_path.txt} 
   \caption{Solution to Medium Maze using BFS}
   \label{fig:bfs_medmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/bfs/bfs_bigMaze_path.txt} 
   \caption{Solution to Big Maze using BFS}
   \label{fig:bfs_bigmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/bfs/bfs_openMaze_path.txt} 
   \caption{Solution to Open Maze using BFS}
   \label{fig:bfs_openmaze}
   \end{figure}
   
   % solutions for DFS
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/dfs/dfs_mediumMaze_path.txt} 
   \caption{Solution to Medium Maze using DFS}
   \label{fig:dfs_medmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/dfs/dfs_bigMaze_path.txt} 
   \caption{Solution to Big Maze using DFS}
   \label{fig:dfs_bigmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/dfs/dfs_openMaze_path.txt} 
   \caption{Solution to Open Maze using DFS}
   \label{fig:dfs_openmaze}
   \end{figure}
   
   % solutions for greedy
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/greedy/greedy_mediumMaze_path.txt} 
   \caption{Solution to Medium Maze using Greedy}
   \label{fig:greedy_medmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/greedy/greedy_bigMaze_path.txt} 
   \caption{Solution to Big Maze using Greedy}
   \label{fig:greedy_bigmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/greedy/greedy_openMaze_path.txt} 
   \caption{Solution to Open Maze using Greedy}
   \label{fig:greedy_openmaze}
   \end{figure}
   
   
   % solutions for A*
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_mediumMaze_path.txt} 
   \caption{Solution to Medium Maze using A*}
   \label{fig:astar_medmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_bigMaze_path.txt} 
   \caption{Solution to Big Maze using A*}
   \label{fig:astar_bigmaze}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_openMaze_path.txt} 
   \caption{Solution to Open Maze using A*}
   \label{fig:astar_openmaze}
   \end{figure}
   
   \section{Maze Solutions for Part 1.2}
   \label{appendix:p12}
   
   % solutions for A*
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_chull_tinySearch_path.txt} 
   \caption{Solution to Tiny Search using A*}
   \label{fig:astar_ts_chull}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_chull_smallSearch_path.txt} 
   \caption{Solution to Small Search using A*}
   \label{fig:astar_ss_chull}
   \end{figure}
   
   \begin{figure}[!htb]
   \centering
   \VerbatimInput[fontsize=\small, fontfamily=courier]{../data/astar/astar_chull_mediumSearch_path.txt} 
   \caption{Solution to Medium Search using A*}
   \label{fig:astar_ms_chull}
   \end{figure}
   
   \section{Open Source Software Used}
   The following list of Open Source software was used to help with this project:
   
   \begin{itemize}
   \item \textbf{gif-h}
   		\begin{itemize}
   		\item A single header in C that allows for basic GIF processing
   		\item \href{https://github.com/ginsweater/gif-h}{https://github.com/ginsweater/gif-h}
   		\end{itemize}
   \item \textbf{libpng}
   		\begin{itemize}
   		\item C library for PNG manipulation
   		\item \href{http://www.libpng.org/pub/png/libpng.html}{http://www.libpng.org/pub/png/libpng.html}
   		\end{itemize}
   \end{itemize}

\end{appendices}   
   
   
   
\end{document}